{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNftkTtdFVEFHwB+p3P1kXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSeokha/RL_Book_Exercises/blob/main/RL_From_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH5 MCLearning"
      ],
      "metadata": {
        "id": "x-d_hV7oottA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_right(self):\n",
        "        self.y += 1\n",
        "        if self.y > 3:\n",
        "            self.y = 3\n",
        "\n",
        "    def move_left(self):\n",
        "        self.y -= 1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "\n",
        "    def move_up(self):\n",
        "        self.x -= 1\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "\n",
        "    def move_down(self):\n",
        "        self.x += 1\n",
        "        if self.x > 3:\n",
        "            self.x = 3\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            return True\n",
        "        else :\n",
        "            return False\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.x, self.y)\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select_action(self):\n",
        "        coin = random.random()\n",
        "        if coin < 0.25:\n",
        "            action = 0\n",
        "        elif coin < 0.5:\n",
        "            action = 1\n",
        "        elif coin < 0.75:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 3\n",
        "        return action\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = Agent()\n",
        "    data = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    gamma = 1.0\n",
        "    reward = -1\n",
        "    alpha = 0.001\n",
        "\n",
        "    for k in range(50000):\n",
        "        done = False\n",
        "        history = []\n",
        "\n",
        "        while not done:\n",
        "            action = agent.select_action()\n",
        "            (x,y), reward, done = env.step(action)\n",
        "            history.append((x,y,reward))\n",
        "        env.reset()\n",
        "\n",
        "        cum_reward = 0\n",
        "        for transition in history[::-1]:\n",
        "            x, y, reward = transition\n",
        "            data[x][y] = data[x][y] + alpha*(cum_reward-data[x][y])\n",
        "            cum_reward = reward + gamma*cum_reward  # 책에 오타가 있어 수정하였습니다\n",
        "\n",
        "    for row in data:\n",
        "        print(row)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjol4lQAouZ8",
        "outputId": "b46936a8-00c2-4658-e206-1550806ac303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-58.820001613934416, -57.07861740280086, -51.399828193102046, -49.70203520800069]\n",
            "[-57.27679042949309, -53.237622808419, -46.13648217439738, -40.309660909678776]\n",
            "[-55.216717086501276, -48.57105422415603, -38.16426576494489, -26.951208969342204]\n",
            "[-54.48645637066313, -45.55604512841754, -28.36910856418912, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH5 TD Learning"
      ],
      "metadata": {
        "id": "K4UZ3B0VozOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_right(self):\n",
        "        self.y += 1\n",
        "        if self.y > 3:\n",
        "            self.y = 3\n",
        "\n",
        "    def move_left(self):\n",
        "        self.y -= 1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "\n",
        "    def move_up(self):\n",
        "        self.x -= 1\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "\n",
        "    def move_down(self):\n",
        "        self.x += 1\n",
        "        if self.x > 3:\n",
        "            self.x = 3\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            return True\n",
        "        else :\n",
        "            return False\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.x, self.y)\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select_action(self):\n",
        "        coin = random.random()\n",
        "        if coin < 0.25:\n",
        "            action = 0\n",
        "        elif coin < 0.5:\n",
        "            action = 1\n",
        "        elif coin < 0.75:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 3\n",
        "        return action\n",
        "\n",
        "\n",
        "def main():\n",
        "    #TD\n",
        "    env = GridWorld()\n",
        "    agent = Agent()\n",
        "    data = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    gamma = 1.0\n",
        "    reward = -1\n",
        "    alpha = 0.01\n",
        "\n",
        "    for k in range(50000):\n",
        "        done = False\n",
        "        while not done:\n",
        "            x, y = env.get_state()\n",
        "            action = agent.select_action()\n",
        "            (x_prime, y_prime), reward, done = env.step(action)\n",
        "            x_prime, y_prime = env.get_state()\n",
        "            data[x][y] = data[x][y] + alpha*(reward+gamma*data[x_prime][y_prime]-data[x][y])\n",
        "        env.reset()\n",
        "\n",
        "    for row in data:\n",
        "        print(row)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadKnww_ozIn",
        "outputId": "c8e6e9a7-f790-4bcc-8c0a-1dbfa580ed75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-59.595650566762544, -57.58225513271604, -54.3183835237772, -52.13358805795074]\n",
            "[-57.76226647930214, -54.96324723349311, -50.63055740672823, -46.56402453174607]\n",
            "[-54.441253105072164, -50.309955354996504, -42.38629890522122, -29.427410151380453]\n",
            "[-51.897474812160034, -47.12607572187338, -33.477453064796855, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 MC Control"
      ],
      "metadata": {
        "id": "-TTCJf1sozCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1  # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # q벨류를 저장하는 변수. 모두 0으로 초기화.\n",
        "        self.eps = 0.9\n",
        "        self.alpha = 0.01\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, history):\n",
        "        # 한 에피소드에 해당하는 history를 입력으로 받아 q 테이블의 값을 업데이트 한다\n",
        "        cum_reward = 0\n",
        "        for transition in history[::-1]:\n",
        "            s, a, r, s_prime = transition\n",
        "            x,y = s\n",
        "            # 몬테 카를로 방식을 이용하여 업데이트.\n",
        "            self.q_table[x,y,a] = self.q_table[x,y,a] + self.alpha * (cum_reward - self.q_table[x,y,a])\n",
        "            cum_reward = cum_reward + r\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.03\n",
        "        self.eps = max(self.eps, 0.1)\n",
        "\n",
        "    def show_table(self):\n",
        "        # 학습이 각 위치에서 어느 액션의 q 값이 가장 높았는지 보여주는 함수\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000): # 총 1,000 에피소드 동안 학습\n",
        "        done = False\n",
        "        history = []\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done: # 한 에피소드가 끝날 때 까지\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            history.append((s, a, r, s_prime))\n",
        "            s = s_prime\n",
        "        agent.update_table(history) # 히스토리를 이용하여 에이전트를 업데이트\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table() # 학습이 끝난 결과를 출력\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-a79DqVoy8h",
        "outputId": "69ef2540-406b-402b-be96-aeee8d2f91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3. 0. 2. 2. 2. 3.]\n",
            " [2. 3. 0. 1. 2. 3. 3.]\n",
            " [3. 3. 0. 1. 0. 3. 0.]\n",
            " [3. 3. 3. 1. 0. 3. 3.]\n",
            " [2. 2. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 QLearning"
      ],
      "metadata": {
        "id": "1BrC0EvCoy1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
        "        self.eps = 0.9\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택해준다\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, transition):\n",
        "        s, a, r, s_prime = transition\n",
        "        x,y = s\n",
        "        next_x, next_y = s_prime\n",
        "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
        "        # Q러닝 업데이트 식을 이용\n",
        "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + np.amax(self.q_table[next_x,next_y,:]) - self.q_table[x,y,a])\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.01  # Q러닝에선 epsilon 이 좀더 천천히 줄어 들도록 함.\n",
        "        self.eps = max(self.eps, 0.2)\n",
        "\n",
        "    def show_table(self):\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000):\n",
        "        done = False\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            agent.update_table((s,a,r,s_prime))\n",
        "            s = s_prime\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t76giceCoysb",
        "outputId": "d0e301c5-d67e-459e-b99f-78270f71583d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3. 3. 0. 0. 3. 2. 3.]\n",
            " [3. 3. 0. 2. 2. 3. 3.]\n",
            " [2. 3. 0. 1. 0. 3. 3.]\n",
            " [2. 2. 2. 1. 0. 3. 3.]\n",
            " [1. 1. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 SARSA"
      ],
      "metadata": {
        "id": "-OIrb1HHowRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1  # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
        "        self.eps = 0.9\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택해준다\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, transition):\n",
        "        s, a, r, s_prime = transition\n",
        "        x,y = s\n",
        "        next_x, next_y = s_prime\n",
        "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
        "        # SARSA 업데이트 식을 이용\n",
        "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + self.q_table[next_x,next_y,a_prime] - self.q_table[x,y,a])\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.03\n",
        "        self.eps = max(self.eps, 0.1)\n",
        "\n",
        "    def show_table(self):\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000):\n",
        "        done = False\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            agent.update_table((s,a,r,s_prime))\n",
        "            s = s_prime\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm-7dzwAowG5",
        "outputId": "e328aa4f-f507-4464-fc16-80ce6d8e37bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3. 0. 0. 3. 2. 3.]\n",
            " [2. 3. 0. 2. 2. 3. 3.]\n",
            " [2. 3. 0. 1. 0. 2. 3.]\n",
            " [2. 2. 2. 1. 0. 3. 3.]\n",
            " [3. 3. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo-rxJHjjvzK"
      },
      "outputs": [],
      "source": [
        "#CH7 Cosine Fitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "def true_fun(X):\n",
        "    noise = np.random.rand(X.shape[0]) * 0.4 - 0.2\n",
        "    return np.cos(1.5 * np.pi * X) + X + noise\n",
        "\n",
        "def plot_results(model):\n",
        "    x = np.linspace(0, 5, 100)\n",
        "    input_x = torch.from_numpy(x).float().unsqueeze(1)\n",
        "    plt.plot(x, true_fun(x), label=\"Truth\")\n",
        "    plt.plot(x, model(input_x).detach().numpy(), label=\"Prediction\")\n",
        "    plt.legend(loc='lower right',fontsize=15)\n",
        "    plt.xlim((0, 5))\n",
        "    plt.ylim((-1, 5))\n",
        "    plt.grid()\n",
        "\n",
        "def main():\n",
        "    data_x = np.random.rand(10000) * 5 # 0~5 사이 숫자 1만개를 샘플링하여 인풋으로 사용\n",
        "    model = Model()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for step in range(10000):\n",
        "        batch_x = np.random.choice(data_x, 32) # 랜덤하게 뽑힌 32개의 데이터로 mini-batch를 구성\n",
        "        batch_x_tensor = torch.from_numpy(batch_x).float().unsqueeze(1)\n",
        "        pred = model(batch_x_tensor)\n",
        "\n",
        "        batch_y = true_fun(batch_x)\n",
        "        truth = torch.from_numpy(batch_y).float().unsqueeze(1)\n",
        "        loss = F.mse_loss(pred, truth) # 손실 함수인 MSE를 계산하는 부분\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.mean().backward() # 역전파를 통한 그라디언트 계산이 일어나는 부분\n",
        "        optimizer.step() # 실제로 파라미터를 업데이트 하는 부분\n",
        "\n",
        "    plot_results(model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "6PP2LbXQkNPa",
        "outputId": "ab4a52e5-56f1-4485-a66b-dba1e6b19d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH8 DQN"
      ],
      "metadata": {
        "id": "csR7AS-alq5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import collections\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "gamma         = 0.98\n",
        "buffer_limit  = 50000\n",
        "batch_size    = 32\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class Qnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Qnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0,1)\n",
        "        else :\n",
        "            return out.argmax().item()\n",
        "\n",
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(10):\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    q = Qnet()\n",
        "    q_target = Qnet()\n",
        "    q_target.load_state_dict(q.state_dict())\n",
        "    memory = ReplayBuffer()\n",
        "\n",
        "    print_interval = 20\n",
        "    score = 0.0\n",
        "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n",
        "            s_prime, r, done, info = env.step(a)\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            memory.put((s,a,r/100.0,s_prime, done_mask))\n",
        "            s = s_prime\n",
        "\n",
        "            score += r\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if memory.size()>2000:\n",
        "            train(q, q_target, memory, optimizer)\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            q_target.load_state_dict(q.state_dict())\n",
        "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
        "                                                            n_epi, score/print_interval, memory.size(), epsilon*100))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_vX0dzBlfEb",
        "outputId": "8e3ddc73-3368-4ebd-9113-1e5a918e58f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_episode :20, score : 9.9, n_buffer : 199, eps : 7.9%\n",
            "n_episode :40, score : 9.6, n_buffer : 391, eps : 7.8%\n",
            "n_episode :60, score : 9.4, n_buffer : 579, eps : 7.7%\n",
            "n_episode :80, score : 9.8, n_buffer : 774, eps : 7.6%\n",
            "n_episode :100, score : 10.1, n_buffer : 976, eps : 7.5%\n",
            "n_episode :120, score : 9.6, n_buffer : 1167, eps : 7.4%\n",
            "n_episode :140, score : 9.7, n_buffer : 1360, eps : 7.3%\n",
            "n_episode :160, score : 9.8, n_buffer : 1556, eps : 7.2%\n",
            "n_episode :180, score : 9.6, n_buffer : 1747, eps : 7.1%\n",
            "n_episode :200, score : 9.9, n_buffer : 1945, eps : 7.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-871dc58d492f>:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_episode :220, score : 13.2, n_buffer : 2210, eps : 6.9%\n",
            "n_episode :240, score : 10.4, n_buffer : 2419, eps : 6.8%\n",
            "n_episode :260, score : 9.8, n_buffer : 2614, eps : 6.7%\n",
            "n_episode :280, score : 9.9, n_buffer : 2813, eps : 6.6%\n",
            "n_episode :300, score : 11.3, n_buffer : 3040, eps : 6.5%\n",
            "n_episode :320, score : 14.7, n_buffer : 3333, eps : 6.4%\n",
            "n_episode :340, score : 46.6, n_buffer : 4265, eps : 6.3%\n",
            "n_episode :360, score : 99.5, n_buffer : 6254, eps : 6.2%\n",
            "n_episode :380, score : 177.2, n_buffer : 9798, eps : 6.1%\n",
            "n_episode :400, score : 202.9, n_buffer : 13857, eps : 6.0%\n",
            "n_episode :420, score : 226.7, n_buffer : 18390, eps : 5.9%\n",
            "n_episode :440, score : 225.8, n_buffer : 22906, eps : 5.8%\n",
            "n_episode :460, score : 202.7, n_buffer : 26960, eps : 5.7%\n",
            "n_episode :480, score : 125.2, n_buffer : 29463, eps : 5.6%\n",
            "n_episode :500, score : 196.3, n_buffer : 33390, eps : 5.5%\n",
            "n_episode :520, score : 135.8, n_buffer : 36105, eps : 5.4%\n",
            "n_episode :540, score : 272.1, n_buffer : 41546, eps : 5.3%\n",
            "n_episode :560, score : 250.9, n_buffer : 46564, eps : 5.2%\n",
            "n_episode :580, score : 253.2, n_buffer : 50000, eps : 5.1%\n",
            "n_episode :600, score : 245.5, n_buffer : 50000, eps : 5.0%\n",
            "n_episode :620, score : 220.8, n_buffer : 50000, eps : 4.9%\n",
            "n_episode :640, score : 192.9, n_buffer : 50000, eps : 4.8%\n",
            "n_episode :660, score : 157.4, n_buffer : 50000, eps : 4.7%\n",
            "n_episode :680, score : 157.9, n_buffer : 50000, eps : 4.6%\n",
            "n_episode :700, score : 175.2, n_buffer : 50000, eps : 4.5%\n",
            "n_episode :720, score : 193.4, n_buffer : 50000, eps : 4.4%\n",
            "n_episode :740, score : 195.2, n_buffer : 50000, eps : 4.3%\n",
            "n_episode :760, score : 183.7, n_buffer : 50000, eps : 4.2%\n",
            "n_episode :780, score : 205.8, n_buffer : 50000, eps : 4.1%\n",
            "n_episode :800, score : 218.4, n_buffer : 50000, eps : 4.0%\n",
            "n_episode :820, score : 158.3, n_buffer : 50000, eps : 3.9%\n",
            "n_episode :840, score : 195.1, n_buffer : 50000, eps : 3.8%\n",
            "n_episode :860, score : 151.7, n_buffer : 50000, eps : 3.7%\n",
            "n_episode :880, score : 300.7, n_buffer : 50000, eps : 3.6%\n",
            "n_episode :900, score : 239.9, n_buffer : 50000, eps : 3.5%\n",
            "n_episode :920, score : 311.6, n_buffer : 50000, eps : 3.4%\n",
            "n_episode :940, score : 261.4, n_buffer : 50000, eps : 3.3%\n",
            "n_episode :960, score : 206.6, n_buffer : 50000, eps : 3.2%\n",
            "n_episode :980, score : 277.1, n_buffer : 50000, eps : 3.1%\n",
            "n_episode :1000, score : 226.4, n_buffer : 50000, eps : 3.0%\n",
            "n_episode :1020, score : 219.6, n_buffer : 50000, eps : 2.9%\n",
            "n_episode :1040, score : 157.8, n_buffer : 50000, eps : 2.8%\n",
            "n_episode :1060, score : 167.8, n_buffer : 50000, eps : 2.7%\n",
            "n_episode :1080, score : 178.2, n_buffer : 50000, eps : 2.6%\n",
            "n_episode :1100, score : 189.8, n_buffer : 50000, eps : 2.5%\n",
            "n_episode :1120, score : 179.8, n_buffer : 50000, eps : 2.4%\n",
            "n_episode :1140, score : 187.2, n_buffer : 50000, eps : 2.3%\n",
            "n_episode :1160, score : 168.6, n_buffer : 50000, eps : 2.2%\n",
            "n_episode :1180, score : 188.6, n_buffer : 50000, eps : 2.1%\n",
            "n_episode :1200, score : 152.2, n_buffer : 50000, eps : 2.0%\n",
            "n_episode :1220, score : 157.2, n_buffer : 50000, eps : 1.9%\n",
            "n_episode :1240, score : 118.0, n_buffer : 50000, eps : 1.8%\n",
            "n_episode :1260, score : 159.4, n_buffer : 50000, eps : 1.7%\n",
            "n_episode :1280, score : 219.8, n_buffer : 50000, eps : 1.6%\n",
            "n_episode :1300, score : 140.3, n_buffer : 50000, eps : 1.5%\n",
            "n_episode :1320, score : 202.2, n_buffer : 50000, eps : 1.4%\n",
            "n_episode :1340, score : 167.2, n_buffer : 50000, eps : 1.3%\n",
            "n_episode :1360, score : 186.6, n_buffer : 50000, eps : 1.2%\n",
            "n_episode :1380, score : 169.6, n_buffer : 50000, eps : 1.1%\n",
            "n_episode :1400, score : 102.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1420, score : 166.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1440, score : 148.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1460, score : 163.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1480, score : 175.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1500, score : 162.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1520, score : 173.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1540, score : 186.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1560, score : 193.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1580, score : 249.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1600, score : 223.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1620, score : 220.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1640, score : 186.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1660, score : 254.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1680, score : 248.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1700, score : 219.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1720, score : 169.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1740, score : 281.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1760, score : 209.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1780, score : 209.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1800, score : 177.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1820, score : 211.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1840, score : 168.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1860, score : 152.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1880, score : 207.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1900, score : 227.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1920, score : 218.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1940, score : 197.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1960, score : 210.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1980, score : 206.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2000, score : 211.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2020, score : 202.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2040, score : 173.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2060, score : 199.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2080, score : 259.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2100, score : 301.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2120, score : 214.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2140, score : 224.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2160, score : 279.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2180, score : 33.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2200, score : 115.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2220, score : 225.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2240, score : 115.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2260, score : 284.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2280, score : 413.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2300, score : 279.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2320, score : 161.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2340, score : 149.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2360, score : 234.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2380, score : 264.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2400, score : 308.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2420, score : 361.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2440, score : 411.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2460, score : 400.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2480, score : 365.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2500, score : 253.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2520, score : 328.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2540, score : 266.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2560, score : 269.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2580, score : 318.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2600, score : 268.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2620, score : 391.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2640, score : 353.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2660, score : 377.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2680, score : 363.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2700, score : 352.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2720, score : 424.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2740, score : 478.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2760, score : 409.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2780, score : 357.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2800, score : 420.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2820, score : 238.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2840, score : 341.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2860, score : 284.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2880, score : 325.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2900, score : 268.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2920, score : 344.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2940, score : 280.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2960, score : 283.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2980, score : 233.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3000, score : 288.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3020, score : 387.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3040, score : 315.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3060, score : 258.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3080, score : 404.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3100, score : 313.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3120, score : 140.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3140, score : 227.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3160, score : 183.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3180, score : 178.6, n_buffer : 50000, eps : 1.0%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(q, q_target, memory, optimizer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH9 Actor Critic"
      ],
      "metadata": {
        "id": "0hj7_8h9lwhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "n_rollout     = 10\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.data = []\n",
        "\n",
        "        self.fc1 = nn.Linear(4,256)\n",
        "        self.fc_pi = nn.Linear(256,2)\n",
        "        self.fc_v = nn.Linear(256,1)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def pi(self, x, softmax_dim = 0):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc_pi(x)\n",
        "        prob = F.softmax(x, dim=softmax_dim)\n",
        "        return prob\n",
        "\n",
        "    def v(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        v = self.fc_v(x)\n",
        "        return v\n",
        "\n",
        "    def put_data(self, transition):\n",
        "        self.data.append(transition)\n",
        "\n",
        "    def make_batch(self):\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
        "        for transition in self.data:\n",
        "            s,a,r,s_prime,done = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r/100.0])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            done_lst.append([done_mask])\n",
        "\n",
        "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                                                               torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "                                                               torch.tensor(done_lst, dtype=torch.float)\n",
        "        self.data = []\n",
        "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
        "\n",
        "    def train_net(self):\n",
        "        s, a, r, s_prime, done = self.make_batch()\n",
        "        td_target = r + gamma * self.v(s_prime) * done\n",
        "        delta = td_target - self.v(s)\n",
        "\n",
        "        pi = self.pi(s, softmax_dim=1)\n",
        "        pi_a = pi.gather(1,a)\n",
        "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(self.v(s), td_target.detach())\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    model = ActorCritic()\n",
        "    print_interval = 20\n",
        "    score = 0.0\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        done = False\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            for t in range(n_rollout):\n",
        "                prob = model.pi(torch.from_numpy(s).float())\n",
        "                m = Categorical(prob)\n",
        "                a = m.sample().item()\n",
        "                s_prime, r, done, info = env.step(a)\n",
        "                model.put_data((s,a,r,s_prime,done))\n",
        "\n",
        "                s = s_prime\n",
        "                score += r\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            model.train_net()\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "-HuUZl51okfX",
        "outputId": "6cdcf29d-482e-4ab9-a802-4db2778ae220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of episode :20, avg score : 21.4\n",
            "# of episode :40, avg score : 23.8\n",
            "# of episode :60, avg score : 25.0\n",
            "# of episode :80, avg score : 24.2\n",
            "# of episode :100, avg score : 22.6\n",
            "# of episode :120, avg score : 27.1\n",
            "# of episode :140, avg score : 28.9\n",
            "# of episode :160, avg score : 28.2\n",
            "# of episode :180, avg score : 29.8\n",
            "# of episode :200, avg score : 32.3\n",
            "# of episode :220, avg score : 37.8\n",
            "# of episode :240, avg score : 40.8\n",
            "# of episode :260, avg score : 46.6\n",
            "# of episode :280, avg score : 56.5\n",
            "# of episode :300, avg score : 46.5\n",
            "# of episode :320, avg score : 53.2\n",
            "# of episode :340, avg score : 57.0\n",
            "# of episode :360, avg score : 70.9\n",
            "# of episode :380, avg score : 65.7\n",
            "# of episode :400, avg score : 69.6\n",
            "# of episode :420, avg score : 74.2\n",
            "# of episode :440, avg score : 77.8\n",
            "# of episode :460, avg score : 86.3\n",
            "# of episode :480, avg score : 94.6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-efc71599e668>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-efc71599e668>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0ms_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         )\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/constraints.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH9 Reinforce"
      ],
      "metadata": {
        "id": "0zfWCdqwomoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Policy, self).__init__()\n",
        "        self.data = []\n",
        "\n",
        "        self.fc1 = nn.Linear(4, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x), dim=0)\n",
        "        return x\n",
        "\n",
        "    def put_data(self, item):\n",
        "        self.data.append(item)\n",
        "\n",
        "    def train_net(self):\n",
        "        R = 0\n",
        "        self.optimizer.zero_grad()\n",
        "        for r, prob in self.data[::-1]:\n",
        "            R = r + gamma * R\n",
        "            loss = -torch.log(prob) * R\n",
        "            loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.data = []\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    pi = Policy()\n",
        "    score = 0.0\n",
        "    print_interval = 20\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done: # CartPole-v1 forced to terminates at 500 step.\n",
        "            prob = pi(torch.from_numpy(s).float())\n",
        "            m = Categorical(prob)\n",
        "            a = m.sample()\n",
        "            s_prime, r, done, info = env.step(a.item())\n",
        "            pi.put_data((r,prob[a]))\n",
        "            s = s_prime\n",
        "            score += r\n",
        "\n",
        "        pi.train_net()\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            print(\"# of episode :{}, avg score : {}\".format(n_epi, score/print_interval))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "VjeYxMsuoo9C",
        "outputId": "9868cd05-a576-436f-a183-2b6da200d79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of episode :20, avg score : 20.55\n",
            "# of episode :40, avg score : 17.6\n",
            "# of episode :60, avg score : 18.1\n",
            "# of episode :80, avg score : 20.3\n",
            "# of episode :100, avg score : 21.9\n",
            "# of episode :120, avg score : 20.45\n",
            "# of episode :140, avg score : 24.95\n",
            "# of episode :160, avg score : 18.45\n",
            "# of episode :180, avg score : 19.4\n",
            "# of episode :200, avg score : 28.8\n",
            "# of episode :220, avg score : 27.15\n",
            "# of episode :240, avg score : 24.6\n",
            "# of episode :260, avg score : 36.3\n",
            "# of episode :280, avg score : 26.55\n",
            "# of episode :300, avg score : 29.45\n",
            "# of episode :320, avg score : 28.2\n",
            "# of episode :340, avg score : 27.75\n",
            "# of episode :360, avg score : 44.55\n",
            "# of episode :380, avg score : 30.65\n",
            "# of episode :400, avg score : 44.45\n",
            "# of episode :420, avg score : 43.25\n",
            "# of episode :440, avg score : 39.45\n",
            "# of episode :460, avg score : 41.1\n",
            "# of episode :480, avg score : 35.9\n",
            "# of episode :500, avg score : 47.85\n",
            "# of episode :520, avg score : 49.65\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubmPPsI1pUzt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}